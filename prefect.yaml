# File for configuring project / deployment build, push and pull steps

# Generic metadata about this project
name: kubernetes-worker-demo
prefect-version: 2.11.3

# build section allows you to manage and build docker images
# TODO: Uses unreleased changes that requires installing from main:
#     pip install git+https://github.com/PrefectHQ/prefect.git
#     pip install git+https://github.com/PrefectHQ/prefect-docker.git
build:
- prefect.projects.steps.run_shell_script:
    id: get-commit-hash
    script: git rev-parse --short HEAD
    stream_output: false
- prefect_docker.projects.steps.build_docker_image:
    requires: prefect-docker
    image_name: "{{ prefect.variables.image_name }}"
    tag: "latest"
    dockerfile: auto
    push: true
    platform: "linux/amd64"


# push section allows you to manage if and how this project is uploaded to remote locations
push: null

# pull section allows you to provide instructions for cloning this project in remote locations
pull:
# - prefect.projects.steps.git_clone_project:
#     repository: https://dev.azure.com/nitinkeshavb/_git/prefect_kubeworker
#     branch: master
#     access_token: t2vvy2mqkftg5ijn43sr37whjddsupdpucezhbukqtaqp7gungka

- prefect.projects.steps.set_working_directory:
    directory: /opt/prefect/prefect_acr


definitions:
  tags: &common_tags
    - "remote"
    - "eks"
    - "{{ get-commit-hash.stdout }}"
  work_pool: &common_work_pool
    name: "kubernetes"
    job_variables:
      image: "{{ image_name }}"


deployments:

- name: "gpa_landing_capf"
  tags: Null
  entrypoint: "flows/async_databricks_api_exec.py:databricks_job_submit"
  parameters:
    databricks_credentials_block_name: "qa-databricks-repo"
    job_id: "157107892089699"
  work_pool: *common_work_pool

- name: "gpa_landing_hff"
  tags: 
    - "depends_on:databricks-job-submit/gpa_landing_capf"
    - "group:gpa"
  entrypoint: "flows/async_databricks_api_exec.py:databricks_job_submit"
  parameters:
    databricks_credentials_block_name: "qa-databricks-repo"
    job_id: "324922768946285"
  work_pool: *common_work_pool


- name: "gpa_landing_datman"
  tags: 
    - "depends_on:databricks-job-submit/gpa_landing_capf"
    - "group:gpa"
  entrypoint: "flows/async_databricks_api_exec.py:databricks_job_submit"
  parameters:
    databricks_credentials_block_name: "qa-databricks-repo"
    job_id: "94525445717850"
  work_pool: *common_work_pool


- name: "gpa_landing_pix"
  tags: 
    - "depends_on:databricks-job-submit/gpa_landing_datman"
    - "group:gpa"
  entrypoint: "flows/async_databricks_api_exec.py:databricks_job_submit"
  parameters:
    databricks_credentials_block_name: "qa-databricks-repo"
    job_id: "324922768946285"
  work_pool: *common_work_pool